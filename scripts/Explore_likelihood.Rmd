---
title: "Exploring Likelihood"
author: "Maddie Gastonguay"
date: '2023-02-17'
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, out.width = '100%')
library(tidyverse)
library(viridis)
library(scales)
library(ggExtra)
library(patchwork)
library(here)
library(furrr)
library(here)

# # Working directory:
here()

# Set Themes
theme_set(theme_classic())

# read in likelihood functions
source(here("scripts", "likelihood_functions.R"))

set.seed(100)
```

## Likelihood Function

The likelihood of observing $X_1$ episomes in one daughter cell and $X_2$ in the other given the parent cell had $X_0$ episomes, and the probability of replication $(P_r)$ and segregation $(P_s)$ is:


$$L(X_1, X_2 | X_0, P_r, P_s) = {X_0 \choose X_1 + X_2 - X_0}P_r^{X_1 + X_2 - X_0}(1-P_r)^{2X_0-X_1 - X_2}2^{ABS(SIGN(X_1-X_2))}\sum_{s = 0}^{X_1+X_2-X_0}\frac12^{X_0-s}{X_1 + X_2 - X_0 \choose s}{P_s}^s(1-P_s)^{X_1  + X_2 -X_0 -s}\sum_{k = 0}^{\frac{X_1 - s}{2}}{X_1 + X_2 -X_0 -s \choose k}{2X_0 - X_1 - X_2 \choose X_1-s - 2k}$$

where $s$ is the number of replicated episome pairs that segregate into separate daughter cells and $k$ is the number of replicated episome pairs that did not segregate and end up in a daughter cell together.




## Function to calculate likelihood of all possible observed data given X0, Pr, and  Ps

Given we start with a cell with X0 episomes, there are a limited number of X1 and X2 values we can observe. This function enumerates the possibilities and calculates the likelihood of each one given X0, Pr, and Ps. Note that this function assumes, without loss of generality, that $X1 \geq X2$. 

```{r}
calculate_likelihood <- function(X0, Pr, Ps, figure = T, text = T){
  
  df <- expand_grid(Pr = Pr, Ps = Ps, X0 = X0, X1 =  0:(2*X0), X2 = 0:(2*X0)) %>%
    filter(X1 + X2 <= 2*X0, # Can't have more than twice the original number of episomes (the case where all replicate)
           X1 + X2 >= X0, # Must have at least the original number of episomes (they don't disappear)
           X1 >= X2) %>% # Assume X1>=X2 so we don't double count events
    bind_cols(pmap_df(., likelihood))
  
  if(round(sum(df$likelihood),6) != 1) {
    cat('sum of likelihoods: ', round(sum(df$likelihood),6))
    stop('ERROR: Probabilities do not sum to 1')
  }
  
  if(figure) {
    p <- df %>%
      mutate(X1 = as.factor(X1), X2 = as.factor(X2)) %>%
      ggplot(aes(X1, X2, fill = likelihood)) +
      geom_tile() +
      scale_fill_viridis_c() +
      labs(title = "Likelihood of possible outcomes",
           subtitle = str_interp("X0 = ${X0}, Pr = ${Pr}, Ps = ${Ps}"))
    
    if(text){
      p <- p + geom_text(aes(label = round(likelihood, 2), color = likelihood), show.legend = F) +
        scale_color_gradient(low = "white", high = "black")
    }
    
    print(p)
  }
  
  return(df)
}

```


## Examples

Test out the function with X0=1, Pr = 0.84, and Ps = 0.92:

```{r}
Pr = 0.84
Ps = 0.92
X0 = 1
(df <- calculate_likelihood(X0, Pr, Ps))
```

This figure shows the likelihood of observing X1 episomes in one daughter cell and X2 in the other. The likelihood of (X1 = 2, X2 = 0) is the same as (X1 = 0, X2 = 2), so I have only plotted cases where $X_1 \geq X_2$. This way, all displayed likelihoods sum to 1.

### What if we start with more episomes?
If we start with 3 episomes instead of 1, there are more possible observed outcomes:

```{r}
Pr = 0.84
Ps = 0.92
X0 = 3
(df <- calculate_likelihood(X0, Pr, Ps) )
```


### What if replication is perfect?
```{r}
Pr = 1
Ps = 0.92
X0 = 3
df <- calculate_likelihood(X0, Pr, Ps)
```

As we expect, all combinations of X1 and X2 that sum less than 2*X0 = 6 have a likelihood of 0.

### What if replication and segregation are perfect?
```{r}
Pr = 1
Ps = 1
X0 = 3
df <- calculate_likelihood(X0, Pr, Ps)
```

As we expect, the only possible outcome is X0 = 3 episomes in each daughter cell.

### What if episomes never segregate?
```{r}
Pr = 0.84
Ps = 0
X0 = 3
df <- calculate_likelihood(X0, Pr, Ps)
```


### Confirm accuracy of the likelihood
```{r}
set.seed(100)
# Simulate a data with Pr = 0.84 and Ps = 0.92, starting with 3 episomes
Pr = 0.80
Ps = 0.90
X0 = 3

simulated_data <- simulate_multiple_cells(X0, Pr, Ps, 100)
```


```{r, eval = F}
# Do the correct Pr and Ps give us the best likelihood for observing this data point?
parameter_values <- seq(0,1,by = 0.01)
very_fine_grain <- calculate_maximum_likelihood(simulated_data, parameter_values, parameter_values)
```

```{r}
very_fine_grain %>% 
  ggplot(aes(Pr, Ps)) + geom_tile(aes(fill = log_likelihood)) + 
  geom_point(data = . %>% filter(log_likelihood == max(log_likelihood)), aes(color = "Maximal Likelihood")) + 
  geom_point(data = data.frame(Pr, Ps),  shape = 4, size = 3, aes(color = "Parameter Values")) + # Add actual parameter values
  scale_color_manual(values = c("black", "red")) + 
  labs(fill = "Log Likelihood")


very_fine_grain %>% 
  ggplot(aes(Pr, Ps)) + geom_tile(aes(fill = exp(log_likelihood + max(log_likelihood)))) + 
  geom_point(data = . %>% filter(log_likelihood == max(log_likelihood)), aes(color = "Maximal Likelihood")) + 
  geom_point(data = data.frame(Pr, Ps),  shape = 4, size = 3, aes(color = "Parameter Values")) + # Add actual parameter values
  scale_color_manual(values = c("black", "red")) + 
  labs(fill = "Likelihood")
```

## Estimating Uncertainty
First we will convert likelihoods to probabilities. Then we will rank each "box" in the parameter grid according to probability and select the first $n$ boxes that sum to 0.95. The extremes of Pr and Ps will become the range of the 95% CI for each parameter.

```{r}
CIs <- calculate_CI(very_fine_grain)$estimates

grid_search <- very_fine_grain %>% 
  ggplot(aes(Pr, Ps)) + geom_tile(aes(fill = log_likelihood)) + 
  geom_tile(data = calculate_CI(very_fine_grain)$probs, fill = NA, color = "black" ) +
  geom_point(data = CIs, aes(MLE_Pr, MLE_Ps, color = "MLE")) + 
  geom_errorbarh(data = CIs, aes(y = MLE_Ps, xmin = min_Pr, xmax = max_Pr), height = 0) + 
  geom_errorbar(data = CIs, aes(x = MLE_Pr, ymin = min_Ps, ymax = max_Ps), width = 0) +
  geom_point(data = data.frame(Pr, Ps),  aes(color = "Parameter Values")) + # Add actual parameter values
  scale_color_manual(values = c("black", "red")) + 
  labs(fill = "Log Likelihood", caption = "Error Bars show 95% CI for Pr and Ps", title = "Grid Search for Maximum Likelihood Estimate of Pr and Ps") 

Pr_marginal_likelihood <- very_fine_grain %>% 
  mutate(likelihood = exp(log_likelihood - max(log_likelihood))) %>% 
  group_by(Pr) %>% summarise(likelihood = sum(likelihood)) %>% 
  ggplot(aes(Pr, likelihood)) + geom_line() + labs(y = "Marginal\nLikelihood")

Ps_marginal_likelihood <- very_fine_grain %>% 
  mutate(likelihood = exp(log_likelihood - max(log_likelihood))) %>% 
  group_by(Ps) %>% summarise(likelihood = sum(likelihood)) %>% 
  ggplot(aes(Ps, likelihood)) + geom_line() + labs(y = "Marginal\nLikelihood")

Pr_marginal_likelihood + 
  theme(axis.title.x = element_blank(), plot.margin = margin(0,0,0,0), 
        axis.text.x = element_blank(), axis.ticks.x = element_blank(), axis.line.x = element_blank()) +
  plot_spacer() + 
  grid_search + theme(plot.margin = margin(0,0,0,0), plot.title = element_blank()) +
  Ps_marginal_likelihood + coord_flip() + 
  theme(axis.title.y = element_blank(), plot.margin = margin(0,0,0,0),
        axis.text.y = element_blank(), axis.ticks.y = element_blank(), axis.line.y = element_blank()) +
  plot_layout(guides = "collect", heights = c(0.5,2), widths = c(2,0.5)) + 
  plot_annotation(title = "Grid Search for Maxmimum Likelihood Estimate of Pr and Ps")
```

## Test out likelihood in varying cases:

With varying X0 between 2 and 4, the likelihood still does well:

```{r}
set.seed(100)
n_cells <- 100 
Pr = 0.80
Ps = 0.90
X0s <- sample(c(2,3,4), prob = c(0.1, 0.8, 0.1), size = n_cells, replace = T)
simulated_data <- data.frame(X0 = X0s, Pr, Ps, id = 1:n_cells) %>% 
  bind_cols(pmap_df(., sim_data))

grid_results <- run_grid_search(simulated_data)
```

```{r, include = F}
plot_grid_search(grid_results)
```

Decreasing the number of cells gives a good ML estimate with a wider confidence interval.
```{r}
set.seed(100)
n_cells <- 30 
Pr = 0.80
Ps = 0.90
X0s <- sample(c(2,3,4), prob = c(0.1, 0.8, 0.1), size = n_cells, replace = T)
simulated_data <- data.frame(X0 = X0s, Pr, Ps, id = 1:n_cells) %>% 
  bind_cols(pmap_df(., sim_data))

grid_results_30cells <- run_grid_search(simulated_data)
```

```{r, include = F}
plot_grid_search(grid_results_30cells)
```

If both Pr and Ps are weak, the ML estimate is not bad, but the confidence interval for Ps is larger than that of Pr
```{r}
set.seed(100)
n_cells <- 100 
Pr <- 0.5
Ps <- 0.5
X0s <- sample(c(2,3,4), prob = c(0.1, 0.8, 0.1), size = n_cells, replace = T)
simulated_data <- data.frame(X0 = X0s, Pr, Ps, id = 1:n_cells) %>% 
  bind_cols(pmap_df(., sim_data))

grid_results_weakP <- run_grid_search(simulated_data)
```

```{r, include = F}
plot_grid_search(grid_results_weakP)
```

### What if we only simulate with X0 = 3?
```{r}
set.seed(100)
n_cells <- 100 
Pr <- 0.5
Ps <- 0.5
X0s <- 3
simulated_data <- data.frame(X0 = X0s, Pr, Ps, id = 1:n_cells) %>% 
  bind_cols(pmap_df(., sim_data))

grid_results_weakP_sameX0 <- run_grid_search(simulated_data)
```
```{r}
set.seed(100)
n_cells <- 100 
Pr <- 0.5
Ps <- 0.5
X0s <- sample(c(2,3,4), size = n_cells, replace = T)
simulated_data <- data.frame(X0 = X0s, Pr, Ps, id = 1:n_cells) %>% 
  bind_cols(pmap_df(., sim_data))

grid_results_weakP_equalprobX0 <- run_grid_search(simulated_data)
```


Decreasing the number of cells increases the size of the confidence interval.
```{r}
set.seed(100)
n_cells <- 30 
Pr <- 0.5
Ps <- 0.5
X0s <- sample(c(2,3,4), prob = c(0.1, 0.8, 0.1), size = n_cells, replace = T)
simulated_data <- data.frame(X0 = X0s, Pr, Ps, id = 1:n_cells) %>% 
  bind_cols(pmap_df(., sim_data))

grid_results_weakP_30cells <- run_grid_search(simulated_data)
```
```{r, include = F}
plot_grid_search(grid_results_weakP_30cells)
```


What about poor segregation but strong replication?
```{r}
set.seed(100)
n_cells <- 100
Pr <- 0.8
Ps <- 0.5
X0s <- sample(c(2,3,4), prob = c(0.1, 0.8, 0.1), size = n_cells, replace = T)
simulated_data <- data.frame(X0 = X0s, Pr, Ps, id = 1:n_cells) %>% 
  bind_cols(pmap_df(., sim_data))

grid_results_strongR_weak_S <- run_grid_search(simulated_data)
```
```{r, include = F}
plot_grid_search(grid_results_strongR_weak_S)
```

Weak Pr and strong Ps leads to overestimation of Ps and underestimation of Pr.
```{r}
set.seed(100)
n_cells <- 100
Pr <- 0.5
Ps <- 0.8
X0s <- sample(c(2,3,4), prob = c(0.1, 0.8, 0.1), size = n_cells, replace = T)
simulated_data <- data.frame(X0 = X0s, Pr, Ps, id = 1:n_cells) %>% 
  bind_cols(pmap_df(., sim_data))

grid_results_strongS_weak_R <- run_grid_search(simulated_data)
```

```{r, include=  F}
plot_grid_search(grid_results_strongS_weak_R)
```

```{r}
set.seed(100)
n_cells <- 100
Pr <- 0.5
Ps <- 0.8
X0 = 3
simulated_data <- data.frame(X0 = X0, Pr, Ps, id = 1:n_cells) %>% 
  bind_cols(pmap_df(., sim_data))

grid_results_strongS_weak_R_sameX0 <- run_grid_search(simulated_data)
```

```{r}
plot_grid_search(grid_results_strongS_weak_R_sameX0)
```


### Examine likelihood behavior systematically
I will test the performance of the likelihood under several conditions:

1. Large sample size (100 cells) and Small sample size (30 cells)
2. Values of Pr ranging from 0.1 to 0.9 by 0.1
3. Values of Ps ranging from 0.1 to 0.9 by 0.1

In all simulations, X0 will be either 2, 3, or 4, with probability of 10%, 80%, and 10%, respectively.

```{r, eval = F}
cases <- expand_grid(n_cells = c(30, 100), Pr = seq(0.1, 0.9, by = 0.1), Ps = seq(0.1, 0.9, by = 0.1))
likelihood_behavior <- cases %>%
  pmap(function(n_cells, Pr, Ps){
    X0s <- sample(c(2,3,4), prob = c(0.1, 0.8, 0.1), size = n_cells, replace = T)
    simulated_data <- data.frame(X0 = X0s, Pr, Ps, id = 1:n_cells) %>%
      bind_cols(pmap_df(., sim_data)) %>%
      mutate(n_cells = n_cells)
    
    run_grid_search(simulated_data, viz = F)
  })

saveRDS(likelihood_behavior, file = "likelihood_behavior_new.rds")
```

```{r}
cases_CI <- cbind(cases, likelihood_behavior %>% 
                    lapply("[[", "estimates") %>% bind_rows())

cases_CI %>% ggplot(aes(Pr, MLE_Pr)) + 
  geom_abline(lty = "dashed") + 
  geom_errorbar(aes(ymin = min_Pr, ymax = max_Pr), width = 0, lwd = 1) +
  geom_point(size = 2) + 
  facet_grid(n_cells~Ps, labeller = label_both) 

cases_CI %>% ggplot(aes(Ps, MLE_Ps)) + 
  geom_abline(lty = "dashed") + 
  geom_errorbar(aes(ymin = min_Ps, ymax = max_Ps), width = 0, lwd = 1) +
  geom_point(size = 2) + 
  facet_grid(n_cells~Pr, labeller = label_both) 

```



```{r}
cases_CI %>% 
  ggplot(aes(Pr, Ps, fill = MLE_Pr-Pr)) + 
  geom_tile() + 
  facet_wrap(~n_cells, labeller = label_both) +
  scale_fill_gradient2(low = "blue", high = "red", mid = "white", limits = c(-0.8, 0.8)) + 
  ggtitle("Error in Pr") +
  
  cases_CI %>% 
  ggplot(aes(Pr, Ps, fill = MLE_Ps-Ps)) + 
  geom_tile() + 
  facet_wrap(~n_cells, labeller = label_both) +
  scale_fill_gradient2(low = "blue", high = "red", mid = "white", limits = c(-0.8, 0.8)) + 
  ggtitle("Error in Ps") +
  plot_layout(ncol = 1, guides = "collect") &
  labs(fill = "MLE - real\nparameter")

```

```{r}
cases_CI %>% 
  ggplot(aes(Pr, Ps, fill = MLE_Pr-Pr)) + 
  geom_tile() + 
  facet_wrap(~n_cells, labeller = label_both) +
  scale_fill_gradient2(low = "blue", high = "red", mid = "white") + 
  ggtitle("Error in Pr")
```

```{r}
## Calculate width of confidence intervals
cases_CI %>% 
  mutate(Pr_width = max_Pr - min_Pr,
         Ps_width = max_Ps - min_Ps) %>% 
  ggplot(aes(Pr, Ps, fill = Pr_width)) + 
  geom_tile() + 
  geom_text(data = . %>% filter(min_Pr <= Pr & max_Pr >= Pr), label = "*", fontface = 2, size = 3) +
  facet_wrap(~n_cells) +
  # scale_fill_gradient2(low = "blue", high = "red", mid = "white", limits = c(-0.5, 0.5)) + 
  ggtitle("CI width for Pr") +
  scale_fill_distiller(limits = c(0,1))+
  
  cases_CI %>% 
  mutate(Pr_width = max_Pr - min_Pr,
         Ps_width = max_Ps - min_Ps) %>% 
  ggplot(aes(Pr, Ps, fill = Ps_width)) + 
  geom_tile() + 
  geom_text(data = . %>% filter(min_Ps <= Ps & max_Ps >= Ps), label = "*", fontface = 2, size = 3) +
  facet_wrap(~n_cells) +
  # scale_fill_gradient2(low = "blue", high = "red", mid = "white", limits = c(-0.5, 0.5)) + 
  ggtitle("CI width for Ps") + 
  scale_fill_distiller(limits = c(0,1)) +
  
  plot_layout(ncol = 1, guides = "collect") &
  labs(fill = "")

```

```{r}
cases_CI %>% 
  mutate(Pr_width = max_Pr - min_Pr,
         Ps_width = max_Ps - min_Ps) %>% 
  ggplot(aes(Pr, Ps, fill = Pr_width)) + 
  geom_tile() + 
  geom_text(data = . %>% filter(min_Pr <= Pr & max_Pr >= Pr), label = "*", fontface = 2, size = 3) +
  facet_wrap(~n_cells) +
  # scale_fill_gradient2(low = "blue", high = "red", mid = "white", limits = c(-0.5, 0.5)) + 
  ggtitle("CI width for Pr") +
  scale_fill_distiller()
```

### Compare grid search estimates to those calculted with ML estimator
```{r}
my_Pr <- likelihood_behavior %>% lapply("[[", "simulated_data") %>% bind_rows(.id = "case") %>% mutate(prop = (X1 + X2 - X0)/X0) %>% group_by(case) %>% summarise(my_pr = round(sum(prop/n_cells),2))

likelihood_behavior %>% lapply('[[', 'estimates') %>% bind_rows(.id = "case") %>% merge(my_Pr) %>% merge(mutate(cases, case = 1:nrow(cases))) %>% pivot_longer(c(MLE_Pr, my_pr)) %>% ggplot(aes(Pr, value, color = name)) + geom_point() + geom_abline() + 
  facet_grid(n_cells ~ Ps)
likelihood_behavior %>% lapply('[[', 'estimates') %>% bind_rows(.id = "case") %>% merge(my_Pr) %>% 
  ggplot(aes(MLE_Pr, my_pr) ) + geom_point() + geom_abline() 
```

### Look at simulated R/X0 values for each X0
```{r}
likelihood_behavior %>% lapply("[[", "simulated_data") %>% 
  bind_rows(.id = "case") %>% 
  mutate(prop = r/X0) %>% 
  group_by(case, Pr, Ps, n_cells) %>% 
  summarise(mean_prop = mean(prop), sd_prop = sd(prop)) %>% 
  ggplot(aes(Pr, mean_prop, color = as.factor(n_cells))) + 
  geom_point() +
  geom_errorbar(aes(ymin = mean_prop-sd_prop, ymax = mean_prop+sd_prop), width = 0) +
  facet_grid(n_cells~Ps, labeller = "label_both") +
  geom_abline()  +
  labs(title = "Replication Ratio (R/X0) from Simulated Data",
       subtitle = "X0 sampled with Pr(X0 = 2) = 0.1, Pr(X0 = 3) = 0.8, and Pr(X0 = 4) = 0.1",
       caption = "Points represent the mean and error bars denote the standard deviation of the replication ratio for all cells simulated at each parameter combination.",
       y = "R/X0")

likelihood_behavior %>% lapply("[[", "simulated_data") %>% 
  bind_rows(.id = "case") %>% 
  mutate(prop = r/X0) %>% 
  group_by(case, Pr, Ps, n_cells, X0) %>% 
  summarise(mean_prop = mean(prop), sd_prop = sd(prop)) %>% 
  ggplot(aes(Pr, mean_prop, color = as.factor(n_cells))) + 
  geom_point() +
  geom_errorbar(aes(ymin = mean_prop-sd_prop, ymax = mean_prop+sd_prop), width = 0) +
  facet_grid(X0~Ps, labeller = "label_both") +
  geom_abline()  +
  labs(title = "Replication Ratio (R/X0) from Simulated Data",
       subtitle = "X0 sampled with Pr(X0 = 2) = 0.1, Pr(X0 = 3) = 0.8, and Pr(X0 = 4) = 0.1",
       caption = "Points represent the mean and error bars denote the standard deviation of the replication ratio for all cells simulated at each parameter combination.",
       y = "R/X0")
```


## Rerun simulations with only one initial number of episomes at conditions where there is a clear underestimation above
```{r, eval = F}
cases2 <- expand_grid(X0 = c(2,3,4), n_cells = c(100), Pr = seq(0.1, 0.9, by = 0.1), Ps = c(0.3, 0.7) )
likelihood_behavior2 <- cases2 %>% 
  pmap(function(X0, n_cells, Pr, Ps){
    simulated_data <- data.frame(X0, Pr, Ps, id = 1:n_cells) %>% 
      bind_cols(pmap_df(., sim_data)) %>% 
      mutate(n_cells = n_cells)
    
    run_grid_search(simulated_data, viz = F)
  })
saveRDS(likelihood_behavior2, file = "likelihood_behavior_sameX0.rds")
```

```{r}
cases_CI2 <- cbind(cases2, likelihood_behavior2 %>% 
                     lapply("[[", "estimates") %>% bind_rows())

cases_CI2 %>% ggplot(aes(Pr, MLE_Pr)) + 
  geom_abline(lty = "dashed") + 
  geom_errorbar(aes(ymin = min_Pr, ymax = max_Pr), width = 0, lwd = 1) +
  geom_point(size = 2) + 
  facet_grid(X0~Ps, labeller = label_both) 
```

### Compare grid serach results to ML estimator
```{r}
my_Pr2 <- likelihood_behavior2 %>% lapply("[[", "simulated_data") %>% bind_rows(.id = "case") %>% mutate(prop = (X1 + X2 - X0)/X0) %>% group_by(case, X0) %>% summarise(my_pr = round(sum(prop/n_cells),2))
likelihood_behavior2 %>% lapply('[[', 'estimates') %>% bind_rows(.id = "case") %>% merge(my_Pr2) %>% 
  ggplot(aes(MLE_Pr, my_pr, color =as.factor(X0)) ) + geom_point() + geom_abline()

```

## Rerun simulations with equal probability of X0 = 2,3,or 4
```{r, eval = F}
cases3 <- expand_grid(n_cells = c(100), Pr = seq(0.1, 0.9, by = 0.1), Ps = c(0.3, 0.7) )
likelihood_behavior3 <- cases3 %>%
  pmap(function(n_cells, Pr, Ps){
    X0s <- sample(c(2,3,4), prob = c(1/3, 1/3, 1/3), size = 100, replace = T)
    simulated_data <- data.frame(X0 = X0s, Pr, Ps, id = 1:n_cells) %>%
      bind_cols(pmap_df(., sim_data)) %>%
      mutate(n_cells = n_cells)
    
    run_grid_search(simulated_data, viz = F)
  })
```
```{r}
my_Pr3 <- likelihood_behavior3 %>% lapply("[[", "simulated_data") %>% bind_rows(.id = "case") %>% mutate(prop = (X1 + X2 - X0)/X0) %>% group_by(case) %>%
summarise(my_pr = round(sum(prop/n_cells),2))
likelihood_behavior3 %>% lapply('[[', 'estimates') %>% bind_rows(.id = "case") %>% merge(my_Pr3) %>% 
  ggplot(aes(MLE_Pr, my_pr) ) + geom_point() + geom_abline()
```

```{r}
rbind(likelihood_behavior3 %>% lapply("[[", "simulated_data") %>% 
        bind_rows(.id = "case") %>% 
        mutate(prop = r/X0) %>% 
        group_by(case, Pr, Ps, n_cells) %>% 
        summarise(mean_prop = mean(prop), sd_prop = sd(prop)) %>% 
        mutate(sim = "new"),
      
      likelihood_behavior %>% lapply("[[", "simulated_data") %>% 
        bind_rows(.id = "case") %>% 
        mutate(prop = r/X0) %>% 
        group_by(case, Pr, Ps, n_cells) %>% 
        summarise(mean_prop = mean(prop), sd_prop = sd(prop)) %>% 
        filter(n_cells == 100) %>% mutate(sim = "old")
) %>% 
  ggplot(aes(Pr, mean_prop, color = sim)) + 
  geom_point() +
  geom_errorbar(aes(ymin = mean_prop-sd_prop, ymax = mean_prop+sd_prop), width = 0) +
  facet_grid(n_cells~Ps, labeller = "label_both") +
  geom_abline()  +
  labs(title = "Replication Ratio (R/X0) from Simulated Data",
       subtitle = "X0 sampled with Pr(X0 = 2) = Pr(X0 = 3) =  Pr(X0 = 4)",
       caption = "Points represent the mean and error bars denote the standard deviation of the replication ratio for all cells simulated at each parameter combination.",
       y = "R/X0") 

```

